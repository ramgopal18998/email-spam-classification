{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['etherium',\n",
       " 'bio',\n",
       " 'react-test',\n",
       " 'vermanikhil96.github.io-master',\n",
       " 'YouCam Perfect',\n",
       " 'spam',\n",
       " 'blockchain',\n",
       " 'ACM-Team-Notebook-master',\n",
       " 'server-client-chatting-master',\n",
       " 'martian',\n",
       " '.ipynb_checkpoints',\n",
       " 'Codeutsava_hackoverflow_NACOF-master',\n",
       " 'react-native',\n",
       " 'ham',\n",
       " 'Django api',\n",
       " 'server',\n",
       " 'Programs',\n",
       " 'Untitled.ipynb',\n",
       " 'test',\n",
       " 'PHPMailer-master',\n",
       " 'index.html']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import email\n",
    "import email.policy\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasspam = [name for name in sorted(os.listdir('./spam')) if len(name)>20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hasspam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasham = [name for name in sorted(os.listdir('./ham')) if len(name)>20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2551"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hasham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processemails(is_spam,filename):\n",
    "    directory = './spam' if is_spam else './ham'\n",
    "    with open(os.path.join(directory,filename),\"rb\") as f:\n",
    "        return email.parser.BytesParser(policy=email.policy.default).parse(f)\n",
    "    \n",
    "hamemails = [processemails(is_spam=False,filename=name) for name in hasham]\n",
    "spamemails = [processemails(is_spam=True,filename=name) for name in hasspam]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "testEmail = spamemails[6].get_payload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the type of content\n",
    "def get_email_structure(email):\n",
    "    if isinstance(email,str):\n",
    "        return email\n",
    "    payload = email.get_payload()\n",
    "    if isinstance(payload,list):\n",
    "        return \"multipart({})\".format(\",\".join([\n",
    "            get_email_structure(sub_email) for sub_email in email\n",
    "        ]))\n",
    "    else:\n",
    "        return email.get_content_type()\n",
    "    \n",
    "\n",
    "def structures_counter(emails):\n",
    "    structures = Counter()\n",
    "    for email in emails:\n",
    "        structure = get_email_structure(email)\n",
    "        structures[structure] += 1\n",
    "    return structures\n",
    "    \n",
    "    \n",
    "ham_structure = structures_counter(hamemails)\n",
    "spam_structure = structures_counter(spamemails)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_structure.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see a html message\n",
    "for email in spamemails:\n",
    "    if get_email_structure(email) == 'text/html':\n",
    "        testEmail = email\n",
    "        break\n",
    "print(testEmail.get_content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save up to 70% on Life Insurance.\n",
      "Why Spend More Than You Have To?\n",
      "\n",
      "Life Quote Savings\n",
      "\n",
      "Ensuring your \n",
      "      family's financial security is very important. Life Quote Savings makes \n",
      "      buying life insurance simple and affordable. We Provide FREE Access to The \n",
      "      Very Best Companies and The Lowest Rates.Life Quote Savings is FAST, EASY and \n",
      "            SAVES you money! Let us help you get started with the best values in \n",
      "            the country on new coverage. You can SAVE hundreds or even thousands \n",
      "            of dollars by requesting a FREE quote from Lifequote Savings. Our \n",
      "            service will take you less than 5 minutes to complete. Shop and \n",
      "            compare. SAVE up to 70% on all types of Life insurance! \n",
      "Click Here For Your \n",
      "            Free Quote!\n",
      "\n",
      "Protecting your family is the best investment you'll ever \n",
      "          make!If you are in receipt of this email \n",
      "      in error and/or wish to be removed from our list, PLEASE CLICK HERE AND TYPE REMOVE. If you \n",
      "      reside in any state which prohibits e-mail solicitations for insurance, \n",
      "      please disregard this \n",
      "      email.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def html_to_text(email):\n",
    "    try:\n",
    "        soup = BeautifulSoup(email.get_content(),'html.parser')\n",
    "        return soup.text.replace('\\n\\n\\n','')\n",
    "    except:\n",
    "        return \"null\"\n",
    "print(html_to_text(testEmail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joseph S. Barrera III wrote:\n",
      "\n",
      "> Chris Haun wrote:\n",
      ">\n",
      ">> A LifeGem is a certified, high quality diamond created from the \n",
      ">> carbon of your loved one as a memorial to their unique and wonderful \n",
      ">> life.\n",
      ">\n",
      ">\n",
      "> Why wait until you're dead? I'm sure there's enough carbon in\n",
      "> the fat from your typical liposuction job to make a decent diamond.\n",
      ">\n",
      "> - Joe\n",
      ">\n",
      "Oh, hell - what about excrement? I'd love to be able to say - No, the \n",
      "sun doesn't shine out of my ass, but there's the occasional diamond. ;-).\n",
      "\n",
      "Owen\n",
      "\n",
      "\n",
      "http://xent.com/mailman/listinfo/fork\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "New Page 1VIAGRA\n",
      "WITHOUT\n",
      "A DOCTORS VISIT!!\n",
      "CLICK\n",
      "HERE\n",
      "*Other\n",
      "Top Medications also available!!*We\n",
      "have Doctors on call around the country to view\n",
      "your information and quickly approve your order.*Totally\n",
      "Discreet System allows you to order today and\n",
      "enjoy your medication tomorrow in most cases.*Finally\n",
      "you can try the wonder drug Viagra that\n",
      "has swept the World without the embarrassment of\n",
      "having to visit your Doctor and explain your condition!!\n",
      "TO\n",
      "ORDER CLICK HERE!\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "TO GET DELETED \n",
      "http://194.44.46.21/remove.php\n",
      " \n",
      " 3606uLdz7-798Gxne6717WLiQ1-104VoKJ8349uvAE9-31l43\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def email_to_plain(email):\n",
    "    #struct = get_email_structure(email)\n",
    "    for part in email.walk():\n",
    "        partContentType = part.get_content_type()\n",
    "        if partContentType not in ['text/plain','text/html']:\n",
    "            continue\n",
    "        try:\n",
    "            partContent = part.get_content()\n",
    "        except: # in case of encoding issues\n",
    "            partContent = str(part.get_payload())\n",
    "        if partContentType == 'text/plain':\n",
    "            return partContent\n",
    "        else:\n",
    "            return html_to_text(part)\n",
    "\n",
    "print(email_to_plain(hamemails[42]))\n",
    "print(email_to_plain(spamemails[42]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to store word counts and apply stemmer\n",
    "import nltk\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Counter({'the': 15, 'pick': 9, '-lbrace': 6, 'of': 5, '-rbrace': 5, 'I': 4, 'is': 4, '-list': 4, 'thi': 3, '+inbox': 3, '-subject': 3, 'ftp': 3, '-sequenc': 3, '18:19:04': 3, 'command': 3, 'delta$': 3, 'from': 3, 'error': 2, '18:19:03': 2, '4852-4852': 2, 'mercuri': 2, '1': 2, 'hit': 2, \"that'\": 2, 'come': 2, 'version': 2, 'use': 2, 'on': 2, 'and': 2, 'one': 2, 'date:': 1, 'wed': 1, '21': 1, 'aug': 1, '2002': 1, '10:54:46': 1, '-0500': 1, 'from:': 1, 'chri': 1, 'garrigu': 1, '<cwg-dated-103037728706fa6d@deepeddycom>': 1, 'message-id:': 1, '<10299452874797tmda@deepeddyvirciocom>': 1, '|': 1, \"can't\": 1, 'reproduc': 1, 'for': 1, 'me': 1, 'it': 1, 'veri': 1, 'repeat': 1, '(like': 1, 'everi': 1, 'time': 1, 'without': 1, 'fail)': 1, 'debug': 1, 'log': 1, 'happen': 1, 'pick_it': 1, '{exec': 1, '-rbrace}': 1, '{4852-4852': 1, 'mercury}': 1, 'exec': 1, 'ftoc_pickmsg': 1, '{{1': 1, 'hit}}': 1, 'mark': 1, 'tkerror:': 1, 'syntax': 1, 'in': 1, 'express': 1, '\"int': 1, 'note': 1, 'if': 1, 'run': 1, 'by': 1, 'hand': 1, 'where': 1, '\"1': 1, 'hit\"': 1, '(obviously)': 1, 'nmh': 1, \"i'm\": 1, '-version': 1, '--': 1, 'nmh-104': 1, '[compil': 1, 'fuchsiacsmuozau': 1, 'at': 1, 'sun': 1, 'mar': 1, '17': 1, '14:55:56': 1, 'ict': 1, '2002]': 1, 'relev': 1, 'part': 1, 'my': 1, 'mh_profil': 1, 'mhparam': 1, '-seq': 1, 'sel': 1, 'sinc': 1, 'work': 1, 'sequenc': 1, '(actual': 1, 'both': 1, 'them': 1, 'explicit': 1, 'line': 1, 'search': 1, 'popup': 1, 'that': 1, 'mh_profile)': 1, 'do': 1, 'get': 1, 'creat': 1, 'kre': 1, 'ps:': 1, 'still': 1, 'code': 1, 'form': 1, 'a': 1, 'day': 1, 'ago': 1, \"haven't\": 1, 'been': 1, 'abl': 1, 'to': 1, 'reach': 1, 'cv': 1, 'repositori': 1, 'today': 1, '(local': 1, 'rout': 1, 'issu': 1, 'think)': 1, '_______________________________________________': 1, 'exmh-work': 1, 'mail': 1, 'list': 1, 'exmh-workers@redhatcom': 1, 'https://listmanredhatcom/mailman/listinfo/exmh-work': 1}),\n",
       "       Counter({'the': 5, 'limeston': 3, 'of': 3, 'and': 3, 'group': 3, 'plan': 2, 'mount': 2, 'from': 2, 'for': 2, 'granit': 2, 'ft': 2, 'a': 2, 'is': 2, 'thi': 2, 'yahoo': 2, 'martin': 1, 'A': 1, 'posted:': 1, 'tasso': 1, 'papadopoulo': 1, 'greek': 1, 'sculptor': 1, 'behind': 1, 'judg': 1, 'that': 1, 'kerdylio': 1, '70': 1, 'mile': 1, 'east': 1, 'salonika': 1, 'not': 1, 'far': 1, 'atho': 1, 'monast': 1, 'commun': 1, 'wa': 1, 'ideal': 1, 'patriot': 1, 'sculptur': 1, 'As': 1, 'well': 1, 'as': 1, \"alexander'\": 1, 'featur': 1, '240': 1, 'high': 1, '170': 1, 'wide': 1, 'museum': 1, 'restor': 1, 'amphitheatr': 1, 'car': 1, 'park': 1, 'admir': 1, 'crowd': 1, 'are': 1, '---------------------': 1, 'So': 1, 'mountain': 1, 'or': 1, 'If': 1, \"it'\": 1, \"it'll\": 1, 'weather': 1, 'pretti': 1, 'fast': 1, '------------------------': 1, 'sponsor': 1, '---------------------~-->': 1, '4': 1, 'dvd': 1, 'free': 1, '+s&p': 1, 'join': 1, 'now': 1, 'http://usclickyahoocom/pt6ybb/nxieaa/mg3haa/7gsolb/tm': 1, '---------------------------------------------------------------------~->': 1, 'To': 1, 'unsubscrib': 1, 'send': 1, 'an': 1, 'email': 1, 'to:': 1, 'forteana-unsubscribe@egroupscom': 1, 'your': 1, 'use': 1, 'subject': 1, 'to': 1, 'http://docsyahoocom/info/terms/': 1}),\n",
       "       Counter({'the': 16, 'and': 10, 'to': 9, 'man': 7, 'secur': 6, 'said': 5, 'of': 5, 'moscow': 4, 'an': 4, 'with': 4, 'servic': 4, 'a': 4, 'explos': 3, 'wa': 3, 'report': 3, 'polic': 3, 'build': 3, 'group': 3, 'threaten': 2, 'thursday': 2, 'offic': 2, 'seiz': 2, 'who': 2, 'he': 2, 'truck': 2, 'in': 2, 'ntv': 2, 'talk': 2, 'interfax': 2, 'itar-tass': 2, 'news': 2, 'agenc': 2, 'one': 2, 'half': 2, 'negoti': 2, 'drove': 2, 'from': 2, 'him': 2, 'yahoo': 2, 'In': 1, 'august': 1, '22': 1, '2002': 1, '1:40': 1, 'PM': 1, '(ap)': 1, '-': 1, 'on': 1, 'unidentifi': 1, 'arm': 1, 'blow': 1, 'up': 1, 'hi': 1, 'front': 1, \"russia'\": 1, 'feder': 1, 'headquart': 1, 'televis': 1, 'automat': 1, 'rifl': 1, 'carri': 1, 'then': 1, 'got': 1, 'out': 1, 'taken': 1, 'into': 1, 'custodi': 1, 'No': 1, 'other': 1, 'detail': 1, 'were': 1, 'immedi': 1, 'avail': 1, 'had': 1, 'demand': 1, 'high': 1, 'govern': 1, 'offici': 1, 'ekho': 1, 'moskvi': 1, 'radio': 1, 'that': 1, 'want': 1, 'russian': 1, 'presid': 1, 'vladimir': 1, 'putin': 1, 'forc': 1, 'rush': 1, 'within': 1, 'block': 1, 'kremlin': 1, 'red': 1, 'squar': 1, 'bolshoi': 1, 'ballet': 1, 'surround': 1, 'claim': 1, 'have': 1, 'ton': 1, 'continu': 1, 'for': 1, 'about': 1, 'hour': 1, 'outsid': 1, 'cite': 1, 'wit': 1, 'later': 1, 'away': 1, 'under': 1, 'escort': 1, 'street': 1, 'near': 1, \"moscow'\": 1, 'olymp': 1, 'penta': 1, 'hotel': 1, 'where': 1, 'author': 1, 'held': 1, 'further': 1, 'press': 1, 'move': 1, 'appear': 1, 'be': 1, 'attempt': 1, 'by': 1, 'get': 1, 'more': 1, 'locat': 1, '------------------------': 1, 'sponsor': 1, '---------------------~-->': 1, '4': 1, 'dvd': 1, 'free': 1, '+s&p': 1, 'join': 1, 'now': 1, 'http://usclickyahoocom/pt6ybb/nxieaa/mg3haa/7gsolb/tm': 1, '---------------------------------------------------------------------~->': 1, 'To': 1, 'unsubscrib': 1, 'thi': 1, 'send': 1, 'email': 1, 'to:': 1, 'forteana-unsubscribe@egroupscom': 1, 'your': 1, 'use': 1, 'is': 1, 'subject': 1, 'http://docsyahoocom/info/terms/': 1})],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Word_Count(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self, stripHeaders=True, lowercaseConversion = True, punctuationRemoval = True, \n",
    "                 urlReplacement = True, numberReplacement = True, stemming = True):\n",
    "        self.stripHeaders =stripHeaders\n",
    "        self.lowercaseConversion = lowercaseConversion\n",
    "        self.punctuationRemoval = punctuationRemoval\n",
    "        self.urlReplacement = urlReplacement\n",
    "        self.numberReplacement = numberReplacement\n",
    "        self.stemming = stemming\n",
    "        self.stemmer = nltk.PorterStemmer()\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        X_to_words = []\n",
    "        for email in X:\n",
    "            text = email_to_plain(email)\n",
    "            if text is None:\n",
    "                text = \"Empty\"\n",
    "            if self.lowercaseConversion:\n",
    "                text.lower()\n",
    "            if self.punctuationRemoval:\n",
    "                text = text.replace('.','')\n",
    "                text = text.replace(',','')\n",
    "                text = text.replace('!','')\n",
    "                text = text.replace('?','')\n",
    "            word_count = Counter(text.split())\n",
    "            if self.stemming:\n",
    "                stemmed_count = Counter()\n",
    "                for word,count in word_count.items():\n",
    "                    stemmed_word = self.stemmer.stem(word)\n",
    "                    stemmed_count[stemmed_word] += count\n",
    "                word_count = stemmed_count\n",
    "            X_to_words.append(word_count)\n",
    "        return np.array(X_to_words)\n",
    "    \n",
    "    \n",
    "X_few = hamemails[:3]\n",
    "Xwordcounts = Word_Count().fit_transform(X_few)\n",
    "Xwordcounts\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vecotrizing the count\n",
    "class Count_to_vector(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,vocabulary_size=1000):\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "    def fit(self,X,y=None):\n",
    "        total_word_count = Counter()\n",
    "        for word_count in X:\n",
    "            for word,count in word_count.items():\n",
    "                total_word_count[word] += min(count,10)\n",
    "            self.most_common = total_word_count.most_common()[:self.vocabulary_size]\n",
    "            self.vocabulary_ = {word:index+1 for index,(word,count) in enumerate(self.most_common)}\n",
    "            \n",
    "            return self\n",
    "        \n",
    "    def transform(self,X,y=None):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        data = []\n",
    "        for row,word_count in enumerate(X):\n",
    "            for word,count in word_count.items():\n",
    "                rows.append(row)\n",
    "                cols.append(self.vocabulary_.get(word,0))\n",
    "                data.append(count)\n",
    "        \n",
    "        return csr_matrix((data,(rows,cols)),shape=(len(X),self.vocabulary_size+1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[162,  15,   9,   6,   5,   5,   4,   4,   4,   3,   3],\n",
       "       [ 99,   5,   0,   0,   3,   0,   0,   2,   0,   2,   0],\n",
       "       [229,  16,   0,   0,   5,   0,   0,   1,   0,   1,   0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer = Count_to_vector(vocabulary_size=10)\n",
    "X_few_vectors = vocab_transformer.fit_transform(Xwordcounts)\n",
    "X_few_vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "email_pipeline = Pipeline([\n",
    "    (\"Word Count\",Word_Count()),\n",
    "    (\"Count to Vector\",Count_to_vector()),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(spamemails + hamemails)\n",
    "y = np.array([0]*len(spamemails)+[1]*len(hamemails))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_augmented_train = email_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "reg = LogisticRegression(solver=\"liblinear\",random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramgopal/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(reg,X_augmented_train,y_train,cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9471537958622829"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_augmented_test = email_pipeline.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression(solver=\"liblinear\",random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=42, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(X_augmented_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_augmented_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8192371475953566"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.993963782696177"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
